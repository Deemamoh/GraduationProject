{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "588c9696-4278-404a-959d-06f8dcb70630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing libraries\n",
    "import pandas as pd  #Data manipulation\n",
    "import string  #Remove punctuation & characters\n",
    "import nltk  #Natural language processing \n",
    "\n",
    "from nltk.corpus import stopwords  #Stop word removal\n",
    "from nltk.tokenize import word_tokenize  #Tokenizition\n",
    "#from nltk.stem import PorterStemmer  #Stemming\n",
    "from nltk.stem import WordNetLemmatizer  #Import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet  #Import WordNet\n",
    "\n",
    "#Feature extractions libraries\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "#Models libraries\n",
    "from sklearn.model_selection import train_test_split #For data splitting\n",
    "#Model Evaluation Function\n",
    "from sklearn.metrics import accuracy_score, classification_report  #Import metrics\n",
    "from sklearn.svm import SVC  #SVM Model\n",
    "from sklearn.naive_bayes import MultinomialNB #Naive Bayes Model -  MultinomialNB \n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9f93e7c3-5464-4500-888d-ed7453585d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read excel file\n",
    "file_path = r\"C:\\Users\\HUAWEI\\Downloads\\bbc-text 2227 - Copy.csv\"\n",
    "data = pd.read_csv(file_path, delimiter=';')\n",
    "text = data['text']  #get text column\n",
    "category = data['category']  #get category column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2357c21a-5fff-4a69-8efc-d08e9831e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "#Remove unwanted characters\n",
    "text = text.str.replace(f'[{string.punctuation}]', '', regex=True)\n",
    "#convert text column into lower case \n",
    "text = text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "09c37200-66c5-45fd-9e50-2ea052563433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [tv, future, in, the, hands, of, viewers, with...\n",
       "1       [worldcom, boss, left, books, alone, former, w...\n",
       "2       [tigers, wary, of, farrell, gamble, leicester,...\n",
       "3       [yeading, face, newcastle, in, fa, cup, premie...\n",
       "4       [ocean, s, twelve, raids, box, office, ocean, ...\n",
       "                              ...                        \n",
       "2220    [cars, pull, down, us, retail, figures, us, re...\n",
       "2221    [kilroy, unveils, immigration, policy, exchats...\n",
       "2222    [rem, announce, new, glasgow, concert, us, ban...\n",
       "2223    [how, political, squabbles, snowball, it, s, b...\n",
       "2224    [souness, delight, at, euro, progress, boss, g...\n",
       "Name: text, Length: 2225, dtype: object"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization\n",
    "def tokenize_text(text):\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "#Apply the tokenization function to the text column\n",
    "text['tokens'] = text.apply(tokenize_text) #Store the tokens in a new column\n",
    "tokens = text['tokens']\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ecb871a2-9bdc-48f0-b8ea-3dddba2ecfe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [tv, future, hands, viewers, home, theatre, sy...\n",
       "1       [worldcom, boss, left, books, alone, former, w...\n",
       "2       [tigers, wary, farrell, gamble, leicester, say...\n",
       "3       [yeading, face, newcastle, fa, cup, premiershi...\n",
       "4       [ocean, twelve, raids, box, office, ocean, twe...\n",
       "                              ...                        \n",
       "2220    [cars, pull, us, retail, figures, us, retail, ...\n",
       "2221    [kilroy, unveils, immigration, policy, exchats...\n",
       "2222    [rem, announce, new, glasgow, concert, us, ban...\n",
       "2223    [political, squabbles, snowball, become, commo...\n",
       "2224    [souness, delight, euro, progress, boss, graem...\n",
       "Name: text, Length: 2225, dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define stop words for English\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#Stop word removal\n",
    "def remove_stop_words(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "#Apply the function to the tokens column\n",
    "tokens = tokens.apply(remove_stop_words)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4d9348be-9c7b-4e21-af51-5f2d892bf824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [tv, future, hand, viewer, home, theatre, syst...\n",
      "1       [worldcom, bos, leave, book, alone, former, wo...\n",
      "2       [tiger, wary, farrell, gamble, leicester, say,...\n",
      "3       [yeading, face, newcastle, fa, cup, premiershi...\n",
      "4       [ocean, twelve, raid, box, office, ocean, twel...\n",
      "                              ...                        \n",
      "2220    [car, pull, u, retail, figure, u, retail, sale...\n",
      "2221    [kilroy, unveils, immigration, policy, exchats...\n",
      "2222    [rem, announce, new, glasgow, concert, u, band...\n",
      "2223    [political, squabble, snowball, become, common...\n",
      "2224    [souness, delight, euro, progress, bos, graeme...\n",
      "Name: lemmatized, Length: 2225, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Initialize the WordNet lemmatizer\n",
    "wn = WordNetLemmatizer()\n",
    "\n",
    "#Function to map Part-of-speech (POS) tags to WordNet tags\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ  #Adjective\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB  #Verb\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN  #Noun\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV  #Adverb\n",
    "    else:\n",
    "        return wordnet.NOUN  #Default to noun\n",
    "\n",
    "#Define a function for lemmatizing words\n",
    "def lemmatizing(tokens):  #Accept a list of tokens\n",
    "    pos_tag = nltk.pos_tag(tokens)  #Get POS tags for the tokens\n",
    "    return [wn.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tag]  #Return lemmatized words\n",
    "\n",
    "\n",
    "data['lemmatized'] = tokens.apply(lemmatizing)  #Store the lemmatized tokens in a new column\n",
    "\n",
    "print(data['lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2a1c613b-4165-4e7e-a440-43f045f78369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>standard life concern at lse bid standard life...</td>\n",
       "      <td>[standard, life, concern, lse, bid, standard, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>connors  rallying cry for british tennis  do y...</td>\n",
       "      <td>[connors, rally, cry, british, tennis, heart, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>us trade gap ballooned in october the us trade...</td>\n",
       "      <td>[u, trade, gap, balloon, october, u, trade, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>radcliffe will compete in london paula radclif...</td>\n",
       "      <td>[radcliffe, compete, london, paula, radcliffe,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>tv show unites angolan families angolan famili...</td>\n",
       "      <td>[tv, show, unite, angolan, family, angolan, fa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "2148  standard life concern at lse bid standard life...   \n",
       "1750  connors  rallying cry for british tennis  do y...   \n",
       "1649  us trade gap ballooned in october the us trade...   \n",
       "1783  radcliffe will compete in london paula radclif...   \n",
       "230   tv show unites angolan families angolan famili...   \n",
       "\n",
       "                                             lemmatized  \n",
       "2148  [standard, life, concern, lse, bid, standard, ...  \n",
       "1750  [connors, rally, cry, british, tennis, heart, ...  \n",
       "1649  [u, trade, gap, balloon, october, u, trade, de...  \n",
       "1783  [radcliffe, compete, london, paula, radcliffe,...  \n",
       "230   [tv, show, unite, angolan, family, angolan, fa...  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['text', 'lemmatized']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "37e6ad6a-a342-4a93-83a5-b5e7527688fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#End of 1st step (data cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "373bc21e-b6b2-4493-8d6f-cb0da1349054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words (BoW) Matrix:\n",
      "      00  000  000m  000strong  01  02  03  04  05  06  ...  zach  zealand  \\\n",
      "0      0    1     0          0   0   0   0   0   0   0  ...     0        0   \n",
      "1      0    1     0          0   0   0   0   0   0   0  ...     0        0   \n",
      "2      0    0     0          0   0   0   0   0   0   0  ...     0        0   \n",
      "3      0    0     0          0   0   0   0   0   0   0  ...     0        0   \n",
      "4      0    0     0          0   0   0   0   0   0   0  ...     0        0   \n",
      "...   ..  ...   ...        ...  ..  ..  ..  ..  ..  ..  ...   ...      ...   \n",
      "2220   0    0     0          0   1   0   4   0   1   2  ...     0        0   \n",
      "2221   0    2     0          0   0   0   0   0   0   0  ...     0        0   \n",
      "2222   0    1     0          0   0   0   0   0   0   0  ...     0        0   \n",
      "2223   0    1     0          0   0   0   0   0   0   0  ...     0        0   \n",
      "2224   0    0     0          0   0   0   0   0   0   0  ...     0        0   \n",
      "\n",
      "      zeppelin  zero  zhang  zimbabwe  zombie  zone  zoom  zurich  \n",
      "0            0     0      0         0       0     0     0       0  \n",
      "1            0     0      0         0       0     0     0       0  \n",
      "2            0     0      0         0       0     0     0       0  \n",
      "3            0     0      0         0       0     0     0       0  \n",
      "4            0     0      0         0       0     0     0       0  \n",
      "...        ...   ...    ...       ...     ...   ...   ...     ...  \n",
      "2220         0     0      0         0       0     0     0       0  \n",
      "2221         0     0      0         0       0     0     0       0  \n",
      "2222         0     0      0         0       0     0     0       0  \n",
      "2223         0     0      0         0       0     0     0       0  \n",
      "2224         0     0      0         0       0     0     0       0  \n",
      "\n",
      "[2225 rows x 7597 columns]\n",
      "\n",
      "TF-IDF Matrix:\n",
      "       00       000  000m  000strong        01   02        03   04        05  \\\n",
      "0     0.0  0.021520   0.0        0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "1     0.0  0.024853   0.0        0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "2     0.0  0.000000   0.0        0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "3     0.0  0.000000   0.0        0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "4     0.0  0.000000   0.0        0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "...   ...       ...   ...        ...       ...  ...       ...  ...       ...   \n",
      "2220  0.0  0.000000   0.0        0.0  0.063294  0.0  0.257846  0.0  0.065767   \n",
      "2221  0.0  0.096262   0.0        0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "2222  0.0  0.028430   0.0        0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "2223  0.0  0.018027   0.0        0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "2224  0.0  0.000000   0.0        0.0  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "\n",
      "            06  ...  zach  zealand  zeppelin  zero  zhang  zimbabwe  zombie  \\\n",
      "0     0.000000  ...   0.0      0.0       0.0   0.0    0.0       0.0     0.0   \n",
      "1     0.000000  ...   0.0      0.0       0.0   0.0    0.0       0.0     0.0   \n",
      "2     0.000000  ...   0.0      0.0       0.0   0.0    0.0       0.0     0.0   \n",
      "3     0.000000  ...   0.0      0.0       0.0   0.0    0.0       0.0     0.0   \n",
      "4     0.000000  ...   0.0      0.0       0.0   0.0    0.0       0.0     0.0   \n",
      "...        ...  ...   ...      ...       ...   ...    ...       ...     ...   \n",
      "2220  0.144284  ...   0.0      0.0       0.0   0.0    0.0       0.0     0.0   \n",
      "2221  0.000000  ...   0.0      0.0       0.0   0.0    0.0       0.0     0.0   \n",
      "2222  0.000000  ...   0.0      0.0       0.0   0.0    0.0       0.0     0.0   \n",
      "2223  0.000000  ...   0.0      0.0       0.0   0.0    0.0       0.0     0.0   \n",
      "2224  0.000000  ...   0.0      0.0       0.0   0.0    0.0       0.0     0.0   \n",
      "\n",
      "      zone  zoom  zurich  \n",
      "0      0.0   0.0     0.0  \n",
      "1      0.0   0.0     0.0  \n",
      "2      0.0   0.0     0.0  \n",
      "3      0.0   0.0     0.0  \n",
      "4      0.0   0.0     0.0  \n",
      "...    ...   ...     ...  \n",
      "2220   0.0   0.0     0.0  \n",
      "2221   0.0   0.0     0.0  \n",
      "2222   0.0   0.0     0.0  \n",
      "2223   0.0   0.0     0.0  \n",
      "2224   0.0   0.0     0.0  \n",
      "\n",
      "[2225 rows x 7597 columns]\n"
     ]
    }
   ],
   "source": [
    "#Try sparate Extractors - Algorithms\n",
    "#Convert lemmatized lists to strings for vectorization\n",
    "data['lemmatized_text'] = data['lemmatized'].apply(lambda x: ' '.join(x))  #Join list into a string\n",
    "\n",
    "#Bag of Words (BoW)\n",
    "bow_vectorizer = CountVectorizer(min_df=5)\n",
    "bow_matrix = bow_vectorizer.fit_transform(data['lemmatized_text'])\n",
    "\n",
    "#Convert to DataFrame for better visualization\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=bow_vectorizer.get_feature_names_out())\n",
    "print(\"Bag of Words (BoW) Matrix:\")\n",
    "print(bow_df)\n",
    "\n",
    "#TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=5)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['lemmatized_text'])\n",
    "\n",
    "#Convert to DataFrame for better visualization\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"\\nTF-IDF Matrix:\")\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "704b1f25-2b64-437b-b557-84a2580b17bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9730337078651685\n",
      "SVM Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     business       0.98      0.92      0.95       101\n",
      "entertainment       0.98      0.99      0.98        81\n",
      "     politics       0.94      0.99      0.96        83\n",
      "        sport       0.98      1.00      0.99        98\n",
      "         tech       0.99      0.98      0.98        82\n",
      "\n",
      "     accuracy                           0.97       445\n",
      "    macro avg       0.97      0.97      0.97       445\n",
      " weighted avg       0.97      0.97      0.97       445\n",
      "\n",
      "Naive Bayes Accuracy: 0.9662921348314607\n",
      "Naive Bayes Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     business       0.96      0.96      0.96       101\n",
      "entertainment       1.00      0.90      0.95        81\n",
      "     politics       0.93      0.98      0.95        83\n",
      "        sport       0.99      1.00      0.99        98\n",
      "         tech       0.95      0.99      0.97        82\n",
      "\n",
      "     accuracy                           0.97       445\n",
      "    macro avg       0.97      0.97      0.97       445\n",
      " weighted avg       0.97      0.97      0.97       445\n",
      "\n",
      "Random Forest Accuracy: 0.952808988764045\n",
      "Random Forest Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     business       0.91      0.94      0.93       101\n",
      "entertainment       1.00      0.91      0.95        81\n",
      "     politics       0.94      0.94      0.94        83\n",
      "        sport       0.99      0.98      0.98        98\n",
      "         tech       0.93      0.99      0.96        82\n",
      "\n",
      "     accuracy                           0.95       445\n",
      "    macro avg       0.95      0.95      0.95       445\n",
      " weighted avg       0.95      0.95      0.95       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, category, test_size=0.2, random_state=42)  #Split data\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)  #Make predictions\n",
    "    accuracy = accuracy_score(y_test, predictions)  #Calculate accuracy\n",
    "    report = classification_report(y_test, predictions)  #Generate classification report\n",
    "    return accuracy, report\n",
    "\n",
    "\n",
    "\n",
    "svm_model = SVC(kernel='linear', class_weight='balanced')  #Initialize SVM model with linear kernel and class weights\n",
    "svm_model.fit(X_train, y_train)  #Train the model\n",
    "svm_accuracy, svm_report = evaluate_model(svm_model, X_test, y_test)  #Evaluate SVM\n",
    "print(\"SVM Accuracy:\", svm_accuracy)  #Print accuracy\n",
    "print(\"SVM Classification Report:\\n\", svm_report)  #Print classification report\n",
    "\n",
    "\n",
    "nb_model = MultinomialNB()  #Initialize Naive Bayes model\n",
    "nb_model.fit(X_train, y_train)  #Train the model\n",
    "nb_accuracy, nb_report = evaluate_model(nb_model, X_test, y_test)  #Evaluate Naive Bayes\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)  #Print accuracy\n",
    "print(\"Naive Bayes Classification Report:\\n\", nb_report)  #Print classification report\n",
    "\n",
    "\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)  #Initialize Random Forest model with class weights\n",
    "rf_model.fit(X_train, y_train)  #Train the model\n",
    "rf_accuracy, rf_report = evaluate_model(rf_model, X_test, y_test)  #Evaluate Random Forest\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)  #Print accuracy\n",
    "print(\"Random Forest Classification Report:\\n\", rf_report)  #Print classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d043e483-b1ef-4088-b0b7-3b88ed071d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 384)\t0.04036462024073686\n",
      "  (0, 394)\t0.0460197312091258\n",
      "  (0, 455)\t0.04383451775992278\n",
      "  (0, 508)\t0.04046503264223666\n",
      "  (0, 531)\t0.20438654638565862\n",
      "  (0, 546)\t0.11285119313176119\n",
      "  (0, 566)\t0.04735248198400006\n",
      "  (0, 567)\t0.04453603901686298\n",
      "  (0, 591)\t0.06103113050462963\n",
      "  (0, 611)\t0.045167879097887866\n",
      "  (0, 654)\t0.08328681587016164\n",
      "  (0, 693)\t0.033235075513500745\n",
      "  (0, 737)\t0.05941532057558684\n",
      "  (0, 747)\t0.051632859067424194\n",
      "  (0, 759)\t0.030552163886798992\n",
      "  (0, 799)\t0.035626820036627004\n",
      "  (0, 839)\t0.0662013169543016\n",
      "  (0, 850)\t0.03100236381646142\n",
      "  (0, 857)\t0.043743657983674834\n",
      "  (0, 904)\t0.05941532057558684\n",
      "  (0, 919)\t0.06374091770856664\n",
      "  (0, 964)\t0.027148671204709436\n",
      "  (0, 970)\t0.05335485038347907\n",
      "  (0, 985)\t0.02759917584260959\n",
      "  (0, 1005)\t0.07124355326599958\n",
      "  :\t:\n",
      "  (444, 5805)\t0.05397950988658272\n",
      "  (444, 5863)\t0.0484986753706583\n",
      "  (444, 5873)\t0.05167779110528446\n",
      "  (444, 5953)\t0.04876553384010303\n",
      "  (444, 6015)\t0.04043633033444995\n",
      "  (444, 6235)\t0.0571837599471461\n",
      "  (444, 6350)\t0.08350726344639042\n",
      "  (444, 6470)\t0.07642953609392786\n",
      "  (444, 6544)\t0.06505122870624365\n",
      "  (444, 6573)\t0.23318701159840247\n",
      "  (444, 6729)\t0.08617409487726088\n",
      "  (444, 6738)\t0.03181524128448396\n",
      "  (444, 6890)\t0.1709387432247905\n",
      "  (444, 6973)\t0.08728588079386759\n",
      "  (444, 6980)\t0.1559100423717308\n",
      "  (444, 7046)\t0.3728138608022804\n",
      "  (444, 7118)\t0.3052843995854106\n",
      "  (444, 7345)\t0.09659235477496371\n",
      "  (444, 7350)\t0.08145989704212707\n",
      "  (444, 7371)\t0.05821500177658213\n",
      "  (444, 7417)\t0.04263673022179456\n",
      "  (444, 7483)\t0.09724581369692181\n",
      "  (444, 7517)\t0.040906814653706824\n",
      "  (444, 7519)\t0.07772900386613416\n",
      "  (444, 7538)\t0.08964609146552906\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0cbce2f8-e8b5-4d3e-8d36-99f0e03685f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414          politics\n",
      "420          business\n",
      "1644    entertainment\n",
      "416              tech\n",
      "1232            sport\n",
      "            ...      \n",
      "741          business\n",
      "205          business\n",
      "1102         business\n",
      "668          business\n",
      "479          business\n",
      "Name: category, Length: 445, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7e422b-e03b-41c1-9bd6-228216869c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
